\documentclass{article}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{amsmath}

\begin{document}
\section{Introduction}

bla bla

Recently, Gao and Scholl presented a set of studies \citep{gao09,gao10,gao11} demonstrating that certain aspects of motion influence detection of chasing and performance in related interactive tasks. In \citet{gao10} the authors focused on the contribution of agent's orientation. They found that visual scenarios where multiple moving geometrical shapes were oriented towards a common target (prey) were more difficult than control conditions where agents' orientation was shifted by 90 degrees. For example, in Experiment 2 the subjects controlled a green disc with computer mouse and tried to avoid contact with a white circle which chased the green circle. The display included six other randomly moving white circles which served as distractors and made the task difficult. As a manipulation the authors added seven white darts that were in half of the trials oriented towards the green circle and in other half perpendicular to it. They compared across the two conditions the proportion of trials where chaser caught the green circle (relative to trials where he didn't). Even though the subjects were told to ignore the darts, they were worse at escape in trials where the darts pointed toward green circle. In Experiment 4 the chaser was the only circle in the display, so it was easily identified. However the subjects needed to additionaly avoid contact with darts. Again, escape rate was lower in trials where the darts were oriented towards green circle than in trials where the orientation was perpendicular. In Experiment 3a the comparison was not between trials, but rather the display was divided into areas that contained darts with different orientation. Subjects' task was to avoid contact with agents. Authors found that in doing so the subjects spent more time in areas with darts oriented perpendicular to the green circle than in areas where darts pointed directly towards it.\\
If we want to conclude that the mentioned effects are due to orientation, one additional assumption is crucial. The experimentally manipulated orientation change has to be perceived as orientation change and not as displacement. The later would be case if the perceived center of the agents body is different from the one designated for the orientation manipulation. In fact, the use of darts as stimuli in \citet{gao10} is problematic since the center of mass is displaced towards the nose of the dart (see Figure \ref{fig.dart}). Thus we can contrive alternative explanations for results of the above mentioned study. In Experiment 3a the subjects avoided areas with darts oriented towards the prey because the agents' positions were perceived as shifted towards and hence closer to the green circle. We presume that in Experiment 4 subjects estimated the critical distance to surrounding agents and based their decisions where to move the green circle on this estimate. If the perceived agents location was shifted towards the agent in wolfpack trials, the subjects would often prematurely leave the current location in exchange for another location which would be a bad choice from the point of view of the nominal dart's center which was used to decide whether the green circle was caught or not (see Figure \ref{fig.exp4}). Results of Experiment 3a and 4 can thus be alternatively interpreted in terms of domain general processes such as distance estimation and decision making. It's hard to come up with domain-general explanation for results of Experiment 2 (and 1). Still, the influence of orientation is confounded by mechanisms that detect chasing based on motion features, since the shifting center of mass can be interpreted as change in position and hence as motion.\\
Experiment 3b was the only experiment that used no darts. The design and results were similar to that of Experiment 3a, except that instead of darts the subject tried to avoid white circles whose orientation was determined by two red dots ('eyes'). If we use the shape of the agent to determine the center of mass, this is identical to the point around which the circle was rotated. Still, this doesn't mean that the agent's perceived position isn't influenced by its orientation. The literature on memory displacement is relevant here \citep{hubbard05}. It has been repeatedly demonstrated that if subjects are asked to give the last position of a stimulus that just disappeared from the screen, subject's responses are not veridical but rather are systematically displaced by factors such as gravity, momentum or shape. Crucially, the displacement can also be influenced by information about stimulus animacy \citep{freyd92}. Furthermore according to \citet{hubbard05} "displacement occurs because it aids in the spatial localization of physical objects and facilitates rapid motor responding to objects in the environment" and he further adds that "accurate spatial localization is important for calibrating an observer's response to a stimulus so that a maximally effective and adaptive interaction with that stimulus might be achieved". Thus the displacement due to representational momentum aniticipates future position and allows to correct the discrepancy between the the position when the action is programmed and when it is performed. Similar, since agent's head/nose orientation predicts the subsequent motion, orientation may be used to predict future position. In Experiment 3b from the prediction of stimulus motion is highly relevant for action and the eyes as well as self-sustained motion are cues to animacy. Hence, we expect to find memory displacement, with these stimuli. Due to the perceived displacement the subject would avoid the wolfpack areas because the wolfpack stimuli are perceived as closing in on the green circle.\\
To test this hypothesis we replicated Experiment 3b but appended a judment task at the end. One of the circles vanished and the subjects were asked to click with mouse its last position. We expect that the judgments will be shifted in direction in which the agent's eyes were pointed. Furthermore, looking at individual differences the magnitude of the wolfpack avoidance should depend on the magnitude perceived displacement. To further substantiate our claim. We added another block where the agents had no eyes but were physically shifted so as to simulate the perceived displacement due to eyes. The estimates of perceived displacement for individuals from the first block were not very reliable, so we chose to test a range of displacement values instead and to estimate a slope of how the wolfpack avoidance varies with the manipulated displacement. The displacement judgments in block one may be a poor proxy for the perceived action-relevant displacement because they are explicitly recalled and may be subject to reflexion and correction. To obtain a more direct estimate of the perceived displacement we added a bisection task. The subjects were shown two agents in two different quadrants (actually these were the same trajectories they saw in block 1 and 2). They were asked to bisect the distance between the two agents. One of the agents was looking towards the mouse cursor another orientation was perpendicular. We expected that the mid-distance would shift towards the perpedicular agent. We were unsure about the effect of the perpendicular agent on the mid-distance displacement. Under strict interpretation we should expect a perpendicular displacement. However, the instruction was not symetric with respect to the two orthogonal components and pilot studies have shown that the judgments are much noisier in the perpendicular direction. To find out we added a fourth block where the agents had no eyes but were physically shifted. This allows us to estimate the relative magnitude of the displacement in the two directions. We expect to find a similar relation in the third block. In final block static stimuli were shown. Subjects were asked to select the position of the agents. The agent either disappeared or did not. Results will tell us wheter the memory displacement affects the static stimuli and also whether the judged center of the agent is not affected by the eyes position.  
   
%Recently, \cite{gao13} claimed (Claim G1) that detection of goal-directed motion and of chasing motion in particular is supported by perceptual mechanisms, where by perceptual mechanisms they mean that "these phenomena may reflect actual visual processing that is specialized for the extraction of animacy from visual motion". One piece of evidence they discuss comes from a series of behavioral studies by these authors. With respect to the behavioral evidence they claim "that a hallmark feature of perception (vs. cognition) is its strict dependence on subtle visual display details: percepts seem to be irresistibly controlled by the nuances of the visual input, regardless of our knowledge, intentions, or decisions" (Claim G.2). In their studies they try to show this dependance on subtle display cues for the case of chasing motion. In \cite{gao09} the subjects were asked whether a chase was present in 10 second motion snippets of four rings. The subtlety of the chase was varied. The chaser moved towards chasee by choosing a new direction from a band of directions distributed uniformly around the straight path to chasee. The width of the band was varied between trials. The authors found that the detection detoriated as the with wider band. In particular there was a sharp decrease in performance between 30 degrees and 60 degrees of the band width. Another experiment used similar stimuli, except that the task of the subject was to control chasee with mouse and the succes rate (whether the chaser came into viccinity of chasee within a time interval) was measured. The authors reported U-shaped performance. The performance was good for chaser with high and low subtlety but it detoriated 90 and 120 degrees band width. The authors \citep{gao09} claimed that "significant correlations are still present with chasing-subtlety values beyond 30° – i.e. the wolf still gets nearer and nearer to the sheep over time – but apparently observers are unable to reliably detect these correlations (i.e. they don't perceive chasing) and so they have no basis for accurate responses" (Claim G.3). The authors thus concluded that the performance is subsumed by domain-specific mechanisms. 
%We think that the distinction between perception and cognition is unproductive and consequently claim G1 is red herring. Instead of boxing phenomena we focus on concrete mechanisms which may underly subjects performance in the chase detection tasks such as perceptual detectors, statistical learning, representational momentum or decision making. This allows us to come up with multiple alternative explanations subsumed by concrete mechanistic models that provide specific predictions. Furthermore, it allows us to link the research on chase detection to the research in other domains.  \\
%What view do we obtain when we focus on mechanisms instead of dichotomuous distinctions? We think that the "strict dependence on subtle visual display details" can arise also from domain-general mechanisms. Consequently, the performance in the chase detection experiments by Gao and Scholl can be explained by the interaction of domain-general mechanisms. In particular, we claim that there are cues in their displays that are not specific to chasing and that these give rise to decision strategies that lead to the observed strict dependence on subtle visual display details. \\
%We now derive alternative explanations of the behavioral experiments provided by Gao and Scholl. To contest claim G.3. By the presence of statistical correlations the authors mean that even the chasers with high subtlety of motion ultimately moved towards the chasee. However this motion should be seen in relation to distractor motion. Distractors changed their trajectory with 120 degrees subtlety around their previous path. Thus if the distractor started towards chasee its path could be very similar to that of nominal chaser. Thus would have hard time to discriminate chaser and distractors - not because the distractor did not conform to their concept of goal-directed motion but because no cue was present in the display to start with. In Experiment 1a we show that a state-of-art support vector classifier can't reliably classify the stimuli with high subtlety. But how do we explain sigmoidal shape of the performance function? We hypothetize that subjects use a single classification model for trials with different subtlety values. They choose some features characteristic of 30 degrees trials and classify all trials showing this features with similar or greater magnitude as chasing present trials. Conversely they choose some features characteristic of 60 degrees trials and classify all trials showing this features with similar or greater magnitude as chasing absent trials. Crucially, in this account the choice of the 30-60 boundary for feature selection is not property of visual system but of decision making mechanisms that attempt to find a single model (and the corresponding boundary) that would maximize the proportion of correct answers (in this task the subjects received feedback after each trial). We thus predict that the sigmoidal function would shift if the proportion of different trials types changed (in the reported studies the proportions were equal). In the extreme case if the trials were presented in blocked instead of randomly mixed design, the performance of subjects should become more linear - similar to the curves obtained by the SVC in experiment 1a. We do not test these predictions because it is unclear which features are used by subjects as cues and whether... the . We however demonstrate the plausibility of our account by fitting a single SVC to sample consisting of the same proportion of trial types as in the experiment 1 by \cite{gao09}. Similar explanation can be contrived for experiment 4 and the mixed-trial design may be also problematic for the experiments reported in \cite{gao11}.\\
%However, how do we explain the results of experiment 3b and 3c from \cite{gao10}? Here the reported effects did not arise between trials but within each trial. We claim that the the agents orientation influences the subject's performance through the representational momentum created by the surface of the agents. In particular the agents will be perceived as shifted towards the chasee. On this account the quadrants with agents oriented towards the chasee are not avoided because of the wolfpack effect but because the agents' position is perceived shifted towards chasee, while in the perpendicular quadrants it is not. Note that representational momentum arises in addition to the center of mass displacement and thus we expect it to arise also with circles with eyes used in experiment 3c in addition to the darts used in experiment 3b. We investigate the influence of the representational momentum on the subjects' in experiment 2 which replicates and extends experiment 3c by \cite{gao10}. \\


\section{Leave Me Alone Methods}

\subsection{Stimulus}
The Stimulus programming followed the description in \citet{gao10} and the examples provided on Brian Scholls web-page. The display was divided into four quadrants, each forming a square of size 5.9 degrees. Three white circles (1.9 degrees in diameter) were located in each quadrant. Each circle had two red eyes drawn on top of it. (These were two red circles of size 0.19 degrees, located 0.71 degrees from the center of the white circle and 0.49 degress apart.) The subject steered a a green circle (agent, 1.2 diameter) with computer mouse. The movement was confined to lie within a circular area with 11.75 degrees radius. The boundary of the circular area was shown on the screen as a thin gray line. The motion of the white circles was generated as follows. The circles moved at constant speed of 7.8 degrees per second. Each circle changed its direction at random intervals with 3 direction changes per second on average. The new direction was chosen randomly from -45 to 45 degrees around the old direction. The rings were pervasive to each other and upon touching the wall of the designated quadrant they bounced off. \\
The orientation was manipulated as follows. Circles were oriented either with their eyes directed towards the agent's location or perpendicular to the agent. There were two quadrants with perpendicular cirles and two quandrants with head-on directed (wolfpack) circles. The type of the quadrant was chosen randomly on each trial. \\
\subsection{Task and Design}
The experiment session consisted of 3 blocks with 42 trials per block. Block 1 went as follows. At the start of each trial the circular boundary and the initial position of the green circle was displayed. Subject started the trial by bringing a cross-hair mouse cursor to the green circle and by clicking on its surface. Furthermore, we ensured that the agent's initial position was at least 4 degrees away from the nearest white circle. Then the white circles appeared and the subject tried to avoid contact by moving the green circles within the circular boundary. This lasted 17 seconds. We appended a location judgment task at the end of the trial. After the movement ended the circles (including the green one) remained stationary. One white circle disappeared. The subject then clicked the last location where he saw the missing circle with a cross-hair cursor. The disappearing circle was chosen randomly from the three nearest circles. Whenever possible we tried to select a circle that did not overlap and so that perpendicular and wolfpack circles were chosen approximately equally often within each block. \\
In the second block the white circles had no eyes. Instead they were physically displaced by by a magnitude that was fixed across agents within trial but varied across trials. We used trial with displacement of -0.15, -0.05, 0.05, 0.1, 0.15 and 0.2. This range was suggested by pilot studies. Later we adapted the range and used 0.05, 0.1,0.15, 0.2 0.25 and 0.3. Otherwise the trials were identical: The displacement was either perpendicular or towards the green circle. The circles were organized into four quadrants based on the type of the displacement. Finally, each trial was followed by a location judgment task. This allowed us to check whether the displacement manipulation was succesful. In addition to the location judgments in the first two blocks we measured the time spent by the green circle in the quadrants with respect to the orientation of the circles.\\
In third block only two agents from two different quadrants were shown: one with perpendicular and one with head-on orientation. The initial position of green circle set at the mid-point on the line connecting the two white circles. The trial started after the subjects clicked the green circle. The subjects were asked to move the green circle such that they stay at the mid-point between the two agents. In the first 18 trials the orientation was indicated by eyes. In the remaining 24 trials the eyes were not displayed and instead the agents were physically displaced in the direction of agent's orientation. The magnitude of displacement was varied with manipulated values identical to those used in block 2.\\
The third block concluded with 13 trials. A white circle was shown for random interval of 2-3 seconds. Then the crosshair appeared and the the circle either disappeared (in the first five trials) or it remained visible. The subjects were asked to select the position of the white circle with cross hair. On first ten trials the eyes were displayed and their orientation was chosen randomly. \\
 
 
\subsection{Eyetracking}
Immediately before taking part in the current experiment the subject participated as an adult control group in an infant eye-tracking study. This experiment took 5-10 minutes. Since the subjects were already seated at a calibrated eyetracker we decided to include eyetracking measurements although no analyses of the eyetracking data were planned and none were performed.

\subsection{Procedure}
The subject were instructed to move a green circle such that they avoid collision with white circles. The subjects were then seated 50-70 cm away from screen (all above specifications in degrees of visual angle are referenced to 50 cm distance) of a Tobii T60 display with built-in remote eye-tracker. Upon the conclusion of the experiment the subjects were debriefed and dismissed. Each block lasted 15 minutes and there was a brief break between them.\\
The experiment was presented and controlled with PsychoPy 1.77 \citep{peirce07} and Tobii SDK 3.0. The analyses were performed in Python 2.7 and STAN 2.0.1.

\subsection{Materials and Data}
Subjects gave informed consent to participate in the study and were further given an option to make their data publicly available. All subjects agreed. The materials and data are available at . We also documented all analyses we made in the form of IPython Notebooks. 

\subsection{Analyses}
In block 1 and 2, we are interested in the direction of the displacement of the last location judgments of the missing circle with respect to its actual position. We expect four predictors to influence the displacement. First, representational gravity pulls objects down along the vertical axis. Second, under the influence of representational momentum subjects interpolate future positions along the motion trajectory of object and recall these as the last position. Third, we call the displacement in the direction of the circles orientation (as indicated by the eyes' location or physical displacement in the third block), orientation displacement. Finally, we expect that the last position of the green circle (controled by mouse) will influence the judgment. In particular we expect the judgment to be pulled towards the last mouse position. We call this effect the lazy-hand gravity.\\
More formally, let $\mathbf \theta_i =[\theta_{ix}, \theta_{iy}]$ be the vector of the difference between the indicated and the actual position of the vanished circle at trial $i$ along the two axes. Let $\phi_{ik}$ be the angle given by the direction of the predictor at trial $i$, with $k$ the predictor (as listed in the previous paragraph). Then we are interested in the estimates of the regression coefficients $\alpha^1_k$ given by the equation\\

\begin{equation}
\mathbf \theta_i \sim  \mathcal{N}\left(\sum_k \alpha_k \begin{bmatrix} \cos \phi_{ik} \\ \sin \phi_{ik} \end{bmatrix}, I\sigma_\theta^{-2} \right)
\end{equation} 

As in \citet{gao10} we compute the proportion of the time spent in the wolfpack quadrants on each trial. We then estimate average proportion for each subject. \\
In block 3 we estimate the displacement as follows. We rotate subjects' judgments in each around the nominal mid-point such that the wolf is located at 180 degrees and perpendicular agent is at 0 degrees. On each trial we discard first 2 seconds and compute the mean displacement during the remaining 15 seconds. We then use this data to estimate the displacement across trials and across subjects.\\
Our general strategy is to first estimate parameters for each subject individually and then to pool estimates with a hierarchical model whenever meaningful. Our within-subject design does not allow us to collect more data points so that in some cases the individual estimates are as robust as we would desire. Hierarchical modeling allows us to pool information across subjects and to obtain more reliable estimates of the individual parameters. More information on hierarchical modeling can be found in \citet{gelman07} and \citet{lee11}.\\

\end{document}

